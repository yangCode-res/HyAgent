from pathlib import Path

from metapub import FindIt, PubMedFetcher

from utils.download import save_pdfs_from_url_list
from utils.pdf2md import deepseek_pdf_to_md_batch
from utils.search import batch_search_reviews_from_user_query

fetch = PubMedFetcher()


def format_reviews(reviews_metadata):  # å°†å¤šç¯‡æ–‡ç« æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
    formatted_reviews = []
    for review in reviews_metadata:
        formatted_reviews.append(format_review(review))
    return "\n\n".join(formatted_reviews)


def format_review(article):  # å°†æ ‡é¢˜ã€æ—¥æœŸã€å¼•ç”¨é‡ã€æ‘˜è¦ã€æ–‡ç« idå–‚ç»™æ¨¡å‹
    return f"""
    æ ‡é¢˜: {article.title}
    å‘è¡¨æ—¥æœŸ: {article.pubdate}
    å¼•ç”¨é‡: {fetch.related_pmids(article.pmid).__len__()}
    æ‘˜è¦: {article.abstract}
    æ–‡ç« id: {article.pmid}
    """


def ReviewSelection(reviews_metadata, topk=5) -> list:  # é€‰æ‹©æœ€åˆé€‚çš„æ–‡ç« 
    selection_prompt = f"""
    ä»ä»¥ä¸‹{len(reviews_metadata)}ç¯‡ç»¼è¿°ä¸­é€‰æ‹©æœ€ç›¸å…³çš„{topk}ç¯‡:
    {format_reviews(reviews_metadata)}
    é€‰æ‹©æ ‡å‡†:
    1. è¦†ç›–æŸ¥è¯¢ä¸»é¢˜çš„ä¸åŒâ½…â¾¯
    2. â¾¼å¼•â½¤é‡å’Œå½±å“å› â¼¦
    3. æœ€æ–°å‘è¡¨â½‡æœŸ
    4. åŒ…å«æœºåˆ¶ç ”ç©¶å’Œä¸´åºŠåº”â½¤
    è¯·ç”¨,éš”å¼€çš„å½¢å¼è¿”å›æ‰€é€‰æ‹©çš„{topk}ç¯‡ç»¼è¿°çš„pidï¼Œä¸éœ€è¦å…¶ä»–é¢å¤–å™è¿°ã€‚
    """
    selected_str = str(generate_text(selection_prompt))
    selected_str = selected_str.replace("[", "").replace("]", "")
    selected_5 = [pid.strip() for pid in selected_str.split(",") if pid.strip()]
    return selected_5


def extract_pdf_paths(download_results) -> list[str]:
    """
    ä» save_pdfs_from_url_list çš„ç»“æœä¸­æå–æˆåŠŸçš„æœ¬åœ° PDF è·¯å¾„åˆ—è¡¨ã€‚
    """
    pdfs = []
    for item in download_results:
        if item.get("status") in {"OK", "EXISTS"} and item.get("path_or_msg"):
            p = Path(item["path_or_msg"])
            if p.is_file() and p.suffix.lower() == ".pdf":
                pdfs.append(str(p))
    return pdfs


if __name__ == "__main__":
    user_query = "Causal mechanisms linking diabetes and cardiovascular disease and potential therapeutic targets"
    print(f"ğŸ” Query: {user_query}\n")

    # 1) æ£€ç´¢å€™é€‰ç»¼è¿°
    results = batch_search_reviews_from_user_query(
        user_query=user_query,     # ä¼ å…¥é—®é¢˜
        years_back=5,              # è¿‘5å¹´
        batch_size=60,             # æ¯æ‰¹å€™é€‰
        topk_batch=10,             # æ¯æ‰¹å–10
        K_total=30,                # æ€»å…±è¦30
        strong_review=False,       # æ˜¯å¦ä½¿ç”¨å¼ºç»¼è¿°ï¼šæ­¤å¤„å¦
        lang_filter=["english"],   # åªè¦è‹±æ–‡æ–‡çŒ®ï¼ˆå¯å»æ‰æ­¤å‚æ•°ï¼‰
        lambda_decay=0.35,         # è¶Šå¤§è¶Šåè¿‘æœŸ
        year_max_ratio=0.4,        # å•å¹´æœ€å¤šå 40%
    )

    # 2) é€‰æ‹© topK ç¯‡ç»¼è¿°
    selected_pmids = ReviewSelection(results, topk=10)  # æœ‰äº›å¯èƒ½æ²¡æœ‰å…¨æ–‡ï¼Œæ•…å– 10
    print("Selected PMIDs:", selected_pmids)

    # 3) æ‰¾åˆ°å…¨æ–‡ URL å¹¶ä¸‹è½½ PDF åˆ°æœ¬åœ°
    selected_reviews = [FindIt(pmid).url for pmid in selected_pmids]
    print("Selected Reviews URLs:", selected_reviews)

    download_results = save_pdfs_from_url_list(
        selected_reviews,
        outdir="downloaded_pdfs",
        overwrite=False,
        timeout=20,
    )

    # 4) æå–æˆåŠŸä¸‹è½½çš„ PDF æœ¬åœ°è·¯å¾„
    pdf_paths = extract_pdf_paths(download_results)
    if not pdf_paths:
        print("âš ï¸ æ²¡æœ‰æˆåŠŸä¸‹è½½åˆ°å¯ç”¨çš„ PDFã€‚")
        exit(0)

    # 5) æ‰¹é‡ OCR â†’ Markdownï¼ˆæ¨¡å‹åªåŠ è½½ä¸€æ¬¡ï¼Œæ•ˆç‡æ›´é«˜ï¼‰
    #    - é»˜è®¤æ¨¡å‹ä½ç½®åœ¨ utils.pdf2md é‡Œæœ‰å¸¸é‡ DEFAULT_DEEPSEEK_MODEL_DIR
    #    - 3090 å»ºè®®èµ° GPUï¼ˆcpu=Falseï¼‰
    markdown_dir = Path(__file__).resolve().parent / "markdown"
    markdown_dir.mkdir(parents=True, exist_ok=True)

    md_outputs = deepseek_pdf_to_md_batch(
        pdf_paths=pdf_paths,
        out_dir=str(markdown_dir),
        first_page=1,          # å¦‚éœ€åªæµ‹å‰å‡ é¡µå¯è®¾ last_pageï¼Œä¾‹å¦‚ last_page=3
        last_page=None,
        dpi=220,
        keep_refs=False,       # ä¸ä¿ç•™å‚è€ƒæ–‡çŒ®/è‡´è°¢ç­‰
        cpu=False,             # 3090 èµ° GPUï¼›è‹¥æƒ³èµ° CPUï¼Œæ”¹ä¸º True
        # model_dir ä¸ä¼ å°±ç”¨ utils.pdf2md é‡Œçš„é»˜è®¤ï¼š/home/nas2/path/yangmingjian/DeepSeek-OCR
        # combine_out å¯ä¼ ä¸€ä¸ªè·¯å¾„æŠŠå¤šç¯‡åˆå¹¶åˆ°ä¸€ä¸ª mdï¼›è¿™é‡ŒæŒ‰ç¯‡è¾“å‡º
    )

    if not md_outputs:
        print("âš ï¸ æœªæˆåŠŸç”Ÿæˆ Markdown æ–‡ä»¶ã€‚")
        exit(0)

    print("âœ… ç”Ÿæˆçš„ Markdown æ–‡ä»¶ï¼š")
    for p in md_outputs:
        print("  -", p)

    # 6) ï¼ˆå¯é€‰ï¼‰åšä¸€æ¬¡è½»é‡æ¸…æ´—ï¼šå»å°¾éƒ¨å¼•ç”¨/å™ªå£°ï¼Œä¿å®ˆç­–ç•¥
    #    - ä½ çš„ clean_markdown æ”¯æŒ tail_portion/min_ref_block/min_keep_ratioï¼Œå¯è‡ªè¡Œè°ƒæ•´
    # for md_file in md_outputs:
    #     try:
    #         raw_md = Path(md_file).read_text(encoding="utf-8", errors="ignore")
    #         cleaned_md, _ = clean_markdown(
    #             raw_md,
    #             tail_portion=0.30,   # ä»…å¯¹æ–‡æœ« 30% è¿›è¡Œå‚è€ƒæ–‡çŒ®/é™„å½•è¯†åˆ«
    #             min_ref_block=10,    # å‚è€ƒæ¡ç›®æœ€å°å—å¤§å°
    #             min_keep_ratio=0.60, # è‡³å°‘ä¿ç•™ 60% æ­£æ–‡ï¼Œé¿å…è¯¯åˆ è¿‡å¤š
    #         )
    #         Path(md_file).write_text(cleaned_md, encoding="utf-8")
    #     except Exception as e:
    #         print(f"[WARN] æ¸…æ´— {md_file} æ—¶å‡ºé”™ï¼š{e}")